{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Permutation(nn.Module):\n",
    "    def __init__(self, n: int, perm: torch.Tensor) -> None:\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.perm = perm.clone().detach()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        if x.ndim == 1:\n",
    "            return x[self.perm]\n",
    "        return x[:, self.perm]\n",
    "\n",
    "    def __eq__(self, other: object) -> bool:\n",
    "        if isinstance(other, Permutation):\n",
    "            return self.n == other.n and torch.all(self.perm == other.perm)\n",
    "        return False\n",
    "\n",
    "    def __ne__(self, value: object) -> bool:\n",
    "        return not self.__eq__(value)\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return hash((self.n, self.perm.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import deque\n",
    "from typing import Iterator\n",
    "\n",
    "\n",
    "def create_all_permutations(n: int) -> Iterator[Permutation]:\n",
    "    for perm in itertools.permutations(range(n)):\n",
    "        yield Permutation(n, torch.tensor(perm, dtype=torch.long))\n",
    "\n",
    "\n",
    "def create_permutations_from_generators(n: int, generators: list[Permutation]) -> Iterator[Permutation]:\n",
    "    assert all(perm.n == n for perm in generators)\n",
    "\n",
    "    def compose(p1: Permutation, p2: Permutation) -> Permutation:\n",
    "        return Permutation(n, p1.forward(p2.perm))\n",
    "\n",
    "    identity = Permutation(n, torch.arange(n))\n",
    "    generated_perms = {identity}\n",
    "    queue = deque([identity])\n",
    "\n",
    "    while queue:\n",
    "        current_perm = queue.popleft()\n",
    "        yield current_perm\n",
    "        for gen in generators:\n",
    "            new_perm = compose(current_perm, gen)\n",
    "            if new_perm not in generated_perms:\n",
    "                generated_perms.add(new_perm)\n",
    "                queue.append(new_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, num_samples: int, d: int, var: float = 1.0) -> None:\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.num_samples = num_samples\n",
    "        self.data = torch.randn(num_samples, d) * var\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tensor:\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CanonicalModel(nn.Module):\n",
    "    def __init__(self, d: int, model: nn.Module, device: torch.device) -> None:\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        torch.sort(x, dim=-1, descending=True, out=x)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymmetryModel(nn.Module):\n",
    "    def __init__(self, d: int, perms: Iterator[Permutation], model: nn.Module, device: torch.device) -> None:\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.perms = perms\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        permuted_x = torch.stack([perm(x) for perm in self.perms])\n",
    "        outputs = self.model(permuted_x)\n",
    "        return torch.mean(outputs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntrinsicModel(nn.Module):\n",
    "    def __init__(self, d: int, device: torch.device) -> None:\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        permuted_x = torch.stack([perm(x) for perm in self.perms])\n",
    "        outputs = self.model(permuted_x)\n",
    "        return torch.mean(outputs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearEquivariant(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int) -> None:\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features  # TODO: USE OUT FEATURES AS WELL, WE WANT TO BE EQUIVARIANT FROM R^M TO R^N\n",
    "        self.bias = torch.ones(in_features)\n",
    "        self.theta1 = torch.ones(1)\n",
    "        self.theta2 = torch.ones(1)\n",
    "\n",
    "        nn.Linear()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        ONES = torch.ones(self.in_features, self.in_features)\n",
    "        ID = torch.eye(self.in_features)\n",
    "        P = ONES * self.theta1 + (ONES - ID) * self.theta2\n",
    "        out = torch.matmul(P, x) + self.bias\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-groups",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
